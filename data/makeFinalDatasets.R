#### Script to generate needed datasets
##
## This script formats, reshapes, and reprojects the data needed to power the map,
## searchbox, and charts in the tool.
##
## Inputs:
## - PC and region shapefiles (uk_shape.shp, uk_region.shp)
## - csv mapping UK postcodes to PCs (2021_abb_geocrosswalk.csv)
## - Excel files of the index and components for each quarter for each PC, region
##   and the UK as a whole (UK_Index_PCs.xls, UK_Index_region.xls, UK_Index.xls)
##
## Outputs:
## - geojson of PCs with their financial vulnerability index for the most recent quarter (pcs.geojson)
## - geojson of regions with their financial vulnerability index for the most recent quarter (regions.geojson)
## - mapping of postal codes to PCs (search_data_v2.csv)
## - mapping of PCs, regions, and the UK to their financial vulnerability index and component values (index_data.csv)
##
#########################################

library(tidyverse)
library(readxl)
library(sf)
library(janitor)
library(lubridate)

# set date of most recent quarter of data
most_recent <- ymd("2020-04-01")

# read in shapefiles of PC and region boundaries
pc_shp <- st_read("shapefiles/parliamentary_constituencies/uk_shape.shp")
pc_shp  # projection is WGS 84 / Pseudo-Mercator

# st_crs(pc_shp)

region_shp <- st_read("shapefiles/regions/uk_region.shp")
region_shp # projection is OSGB 1936 / British National Grid

# st_crs(region_shp)

# read in index and component data
pc_data <- read_excel("source/UK_Index_PCs.xls") %>%
  clean_names() %>%
  mutate(geo = "PC") %>%
  rename("geo_name" = parliamentary_constituency,
         "geo_id" = pc_code)

region_data <- read_excel("source/UK_Index_region.xls") %>%
  clean_names() %>%
  mutate(geo = "Region") %>%
  rename("geo_name" = country_or_region,
         "geo_id" = nuts1_code) %>%
  select(-country_or_region_code) %>%
  mutate(country_or_region = NA)

national_data <- read_excel("source/UK_Index.xls") %>%
  clean_names() %>%
  mutate(geo = "National",
         geo_name = "UK average",
         geo_id = "UK",
         country_or_region = NA)


# bind PC, region, and national datasets together
index_data <- bind_rows(pc_data, region_data, national_data)

# add in the region ID for the parent region/country
regions <- region_data %>%
  select(region_id = geo_id, region_name = geo_name) %>%
  distinct()

index_data <- index_data %>%
  left_join(regions, by = c("country_or_region" = "region_name")) %>%
  select(geo_id,
         geo_name,
         year,
         quarter,
         country_or_region_id = region_id,
         country_or_region,
         everything())

# bin the values into low, low/medium, medium/high, high, and very high buckets
index_data <- index_data %>%
  mutate(distress_level = case_when(
    financial_vulnerability_index <= 30 ~ "low",
    financial_vulnerability_index > 30 & financial_vulnerability_index <= 40 ~ "low/medium",
    financial_vulnerability_index > 40 & financial_vulnerability_index <= 50 ~ "medium/high",
    financial_vulnerability_index > 50 & financial_vulnerability_index <= 65 ~ "high",
    financial_vulnerability_index > 65 ~ "very high"
  ))

index_data$distress_level <- factor(index_data$distress_level,
                              levels = c("low", "low/medium", "medium/high", "high", "very high"))

# round the financial vulnerability index and component values to one decimal place and
# multiply the component values by 100 to turn them into percentages
index_data <- index_data %>%
  mutate(financial_vulnerability_index = round(financial_vulnerability_index, digits = 1),
         share_of_lowell_consumers_in_default = round(share_of_lowell_consumers_in_default * 100, digits = 1),
         share_claiming_social_benefits = round(share_claiming_social_benefits * 100, digits = 1),
         share_with_subprime_lending = round(share_with_subprime_lending * 100, digits = 1),
         share_using_alternative_financial_products = share_using_alternative_financial_products * 100,
         share_without_emergency_savings = share_without_emergency_savings * 100,
         average_credit_use = round(average_credit_use * 100, digits = 1))

# convert quarter and year into a date that can be used for time axis
index_data <- index_data %>%
  mutate(month = case_when(
    quarter == "Q1" ~ 1,
    quarter == "Q2" ~ 4,
    quarter == "Q3" ~ 7,
    quarter == "Q4" ~ 10
  ),
  date = make_date(year, month, 1)) %>%
  select(-month)

# create a numeric ID for each PC and region (Mapbox doesn't accept non-numeric IDs)
numeric_ids <- index_data %>%
  select(geo, geo_id, geo_name) %>%
  distinct() %>%
  arrange(desc(geo), geo_id, geo_name) %>%
  mutate(mapbox_id = row_number())

index_data <- left_join(index_data, numeric_ids)

# export data
write_csv(index_data, "index_data.csv")





### MAKE GEOJSONS

# merge financial vulnerability index data for the most recent quarter onto shapefile (this produces a tibble)
pc_merged <- index_data %>%
  filter(date == most_recent,
         geo == "PC") %>%
  select(geo_id, geo_name, distress_level, mapbox_id) %>%
  right_join(pc_shp, by = c("geo_id" = "PCON17CD")) %>%
  select(-geo_name)

region_merged <- index_data %>%
  filter(date == most_recent,
         geo == "Region") %>%
  select(geo_id, geo_name, distress_level, mapbox_id) %>%
  right_join(region_shp, by = c("geo_id" = "nuts118cd")) %>%
  select(-geo_name)

# convert merged tibble back into a spatial dataframe (need to do this so we can reproject the data)
pc_merged_sf <- st_as_sf(pc_merged)
region_merged_sf <- st_as_sf(region_merged)

# reproject both spatial dataframe to WGS84 / EPSG:4326 (needed for Mapbox)
pc_merged_wgs <- st_transform(pc_merged_sf, 4326)
region_merged_wgs <- st_transform(region_merged_sf, 4326)

# export merged dataset as a geojson file
st_write(pc_merged_wgs, "pcs.geojson", delete_dsn = T)
st_write(region_merged_wgs, "regions.geojson", delete_dsn = T)





### MAKE SEARCHBOX DATA

# read in postal code to PC mapping
postal_code_pc_map <- read_csv("source/2021_abb_geocrosswalk/2021_abb_geocrosswalk.csv")

# rename columns and add a column indicating which search version this
# data applies to (i.e., when searching for a PC or for a region)
postal_code_pc_map <- postal_code_pc_map %>%
  select(label = pcd,
         id = pcon) %>%
  mutate(search_level = "PC")

# also map postal codes to regions - 3/18/21 update: no longer letting users
# search for region by postal code because it resulted in users having to download
# a file that's over 100MB
# postal_code_region_map <- index_data %>%
#   select(geo_id, country_or_region_id) %>%
#   distinct() %>%
#   inner_join(postal_code_pc_map, by = c("geo_id" = "id")) %>%
#   select(label, id = country_or_region_id, search_level) %>%
#   mutate(search_level = "Region")

# grab mapping of PC or region names to their IDs from the full index dataset
pc_region_map <- index_data %>%
  filter(geo != "National") %>%
  mutate(search_level = ifelse(geo == "Region", "Region", "PC")) %>%
  select(label = geo_name,
         id = geo_id,
         search_level) %>%
  distinct()

search_data <- rbind(postal_code_pc_map,
                     #postal_code_region_map,
                     pc_region_map)

write_csv(search_data, "search_data_v2.csv")
