#### Script to generate needed datasets
##
## Outputs:
## - geojson of PCs with their financial vulnerability index for the most recent quarter
## - geojson of regions with their financial vulnerability index for the most recent quarter
## - mapping of postal codes to PCs and regions
## - mapping of PCs, regions, and the UK to their financial vulnerability index and component values
##
#########################################

library(tidyverse)
library(readxl)
library(sf)
library(janitor)
library(lubridate)

# set date of most recent quarter of data
most_recent <- ymd("2020-04-01")

# read in shapefiles of PC and region boundaries
pc_shp <- st_read("shapefiles/parliamentary_constituencies/uk_shape.shp")
pc_shp  # projection is WGS 84 / Pseudo-Mercator

# st_crs(pc_shp)

region_shp <- st_read("shapefiles/regions/uk_region.shp")
region_shp # projection is OSGB 1936 / British National Grid

# st_crs(region_shp)

# read in index and component data
pc_data <- read_excel("source/UK_Index_PCs.xls") %>%
  clean_names() %>%
  mutate(geo = "PC") %>%
  rename("geo_name" = parliamentary_constituency,
         "geo_id" = pc_code)

region_data <- read_excel("source/UK_Index_region.xls") %>%
  clean_names() %>%
  mutate(geo = "region") %>%
  rename("geo_name" = country_or_region,
         "geo_id" = nuts1_code) %>%
  select(-country_or_region_code) %>%
  mutate(country_or_region = NA)

national_data <- read_excel("source/UK_Index.xls") %>%
  clean_names() %>%
  mutate(geo = "national",
         geo_name = "UK national average",
         geo_id = "UK",
         country_or_region = NA) 
  

# bind PC, region, and national datasets together
index_data <- bind_rows(pc_data, region_data, national_data)

# create postal code-PC-region mapping
regions <- region_data %>%
  select(region_id = geo_id, region_name = geo_name) %>%
  distinct()

# add in the region ID for the parent region/country
index_data <- index_data %>%
  left_join(regions, by = c("country_or_region" = "region_name")) %>%
  select(geo_id, 
         geo_name, 
         year, 
         quarter, 
         country_or_region_id = region_id, 
         country_or_region, 
         everything())

# bin the values into low, low/medium, medium/high, high, and very high buckets
index_data <- index_data %>%
  mutate(distress_level = case_when(
    financial_vulnerability_index <= 30 ~ "low",
    financial_vulnerability_index > 30 & financial_vulnerability_index <= 40 ~ "low/medium",
    financial_vulnerability_index > 40 & financial_vulnerability_index <= 50 ~ "medium/high",
    financial_vulnerability_index > 50 & financial_vulnerability_index <= 65 ~ "high",
    financial_vulnerability_index > 65 ~ "very high"
  ))

index_data$distress_level <- factor(index_data$distress_level, 
                              levels = c("low", "low/medium", "medium/high", "high", "very high"))

# round the financial vulnerability index to one decimal place and 
# the component values to two decimal places
index_data <- index_data %>%
  mutate(financial_vulnerability_index = round(financial_vulnerability_index, digits = 1),
         share_of_lowell_consumers_in_default = round(share_of_lowell_consumers_in_default, digits = 2),
         share_claiming_social_benefits = round(share_claiming_social_benefits, digits = 2),
         share_with_subprime_lending = round(share_with_subprime_lending, digits = 2),
         average_credit_use = round(average_credit_use, digits = 2))

# convert quarter and year into a date that can be used for time axis
index_data <- index_data %>%
  mutate(month = case_when(
    quarter == "Q1" ~ 1,
    quarter == "Q2" ~ 4,
    quarter == "Q3" ~ 7,
    quarter == "Q4" ~ 10
  ),
  date = make_date(year, month, 1)) %>%
  select(-month)

# export data
write_csv(index_data, "index_data.csv")





### MAKE GEOJSONS

# merge financial vulnerability index data for the most recent quarter onto shapefile (this produces a tibble)
pc_merged <- index_data %>%
  filter(date == most_recent,
         geo == "PC") %>%
  select(geo_id, geo_name, financial_vulnerability_index) %>%
  right_join(pc_shp, by = c("geo_id" = "PCON17CD")) %>%
  select(-geo_name)

region_merged <- index_data %>%
  filter(date == most_recent,
         geo == "region") %>%
  select(geo_id, geo_name, financial_vulnerability_index) %>%
  right_join(region_shp, by = c("geo_id" = "nuts118cd")) %>%
  select(-geo_name)

# convert merged tibble back into a spatial dataframe (need to do this so we can reproject the data)
pc_merged_sf <- st_as_sf(pc_merged)
region_merged_sf <- st_as_sf(region_merged)

# reproject regions spatial dataframe to WGS84 / Pseudo-Mercator (needed for Mapbox)
# PC shapefile already uses WGS84 / Pseudo-Mercator projection so only need to reproject the regions spatial dataframe
region_merged_wgs <- st_transform(region_merged_sf, 3857)

# export merged dataset as a geojson file
st_write(pc_merged_sf, "pcs.geojson", delete_dsn = T)
st_write(region_merged_wgs, "regions.geojson", delete_dsn = T)





### MAKE SEARCHBOX DATA

# read in postal code to PC mapping
postal_code_pc_map <- read_csv("source/postcode lookup ONS_abbreviated.csv")

# rename columns and add a column indicating which search version this
# data applies to (i.e., when searching for a PC or for a region)
postal_code_pc_map <- postal_code_pc_map %>%
  select(label = pcd,
         id = pcon) %>%
  mutate(search_level = "PC")

# grab mapping of PC or region names to their IDs from the full index dataset
pc_region_map <- index_data %>%
  filter(geo != "National") %>%
  mutate(search_level = ifelse(geo == "region", "Region", "PC")) %>%
  select(label = geo_name, 
         id = geo_id, 
         search_level) %>%
  distinct()

search_data <- rbind(postal_code_pc_map, pc_region_map)

write_csv(search_data, "search_data.csv")
